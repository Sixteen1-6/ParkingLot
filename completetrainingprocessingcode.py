# -*- coding: utf-8 -*-
"""CompleteTrainingProcessingCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgyW_R2P_w9GuMhNlw3Tqhrg_sCwLXED

# Parking Space Detection System - YOLO and KNN Complete Pipeline

This notebook implements a complete training pipeline for parking space detection using YOLOv8 and KNN.
Includes dataset preparation, model training with checkpointing, evaluation, and comprehensive comparison.

## 1. Environment Setup and Package Installation
"""

# Install required packages for computer vision and machine learning
!pip install -q ultralytics opencv-python lxml pandas scikit-learn matplotlib seaborn tqdm pillow joblib

print("Installation complete!")

"""## 2. Import Dependencies"""

# Core Python libraries
import os
import glob
import shutil
import random
import subprocess
from pathlib import Path
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

# Data manipulation and analysis
import numpy as np
import pandas as pd
import yaml

# Computer vision libraries
import cv2

# Machine learning utilities
from sklearn.model_selection import StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# Visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.auto import tqdm

# XML parsing for dataset annotations
from lxml import etree

# Deep learning frameworks
import torch
import torch.serialization
from ultralytics import YOLO
from ultralytics.nn.tasks import DetectionModel

# Fix for PyTorch 2.6+ weights_only serialization issue
# This allows YOLO DetectionModel to be loaded safely
torch.serialization.add_safe_globals([DetectionModel])

# Import polars early to prevent circular import issues
import polars as pl
print("Polars imported successfully")

# Display system information
print("All imports successful!")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")
    print(f"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

"""## 3. Set Random Seeds for Reproducibility"""

def setRandomSeed(seedValue=42):
    """
    Set random seeds for all libraries to ensure reproducible results.

    Args:
        seedValue (int): Random seed value for reproducibility
    """
    random.seed(seedValue)
    np.random.seed(seedValue)
    torch.manual_seed(seedValue)
    torch.cuda.manual_seed_all(seedValue)
    os.environ['PYTHONHASHSEED'] = str(seedValue)

    # Ensure deterministic behavior in CUDA operations
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Set the random seed
setRandomSeed(42)
print("Random seeds set for reproducibility")

"""## 4. Configuration Setup"""

# IMPORTANT: Set this to True to use pretrained model, False to train new model
USE_PRETRAINED_MODEL = False  # Toggle this to switch between pretrained and training modes IMPORTANT TO SWITCH WHEN TRAINING OR USING PREVIOUS MODEL
PRETRAINED_MODEL_PATH = "/content/best.pt"  # Path to your uploaded pretrained model

# Directory configuration for dataset and checkpoints
datasetDirectory = "/content/parking_dataset"
checkpointDirectory = f"{datasetDirectory}/checkpoints"
os.makedirs(checkpointDirectory, exist_ok=True)

# Training hyperparameters configuration
trainingConfiguration = {
    'model': 'yolov8n.pt',          # Base model architecture (nano for faster training)
    'epochs': 1,                   # Total training epochs
    'batch': 16,                    # Batch size
    'imgsz': 1024,                  # Input image size
    'patience': 20,                 # Early stopping patience
    'optimizer': 'Adam',            # Optimization algorithm
    'lr0': 0.001,                   # Initial learning rate
    'device': 0,                    # GPU device ID (0 for first GPU)
    'checkpoint_interval': 5        # Save checkpoint every N epochs
}

print("Configuration set")
print(f"Using Pretrained Model: {USE_PRETRAINED_MODEL}")
if USE_PRETRAINED_MODEL:
    print(f"Pretrained Model Path: {PRETRAINED_MODEL_PATH}")
print(f"Dataset directory: {datasetDirectory}")
print(f"Checkpoint directory: {checkpointDirectory}")
print("\nTraining configuration:")
for configKey, configValue in trainingConfiguration.items():
    print(f"   {configKey}: {configValue}")

"""## 5. Prepare Environment for Dataset Download"""

# Commented out IPython magic to ensure Python compatibility.
# Change to content directory and create dataset folders
# %cd /content
!mkdir -p /content/real_datasets

# Install aria2 for parallel downloads (faster than wget)
!apt-get install -y aria2 > /dev/null 2>&1
print("aria2 installed")
print("Directories created")

"""## 6. Download PKLot Dataset

PKLot is a comprehensive parking lot dataset containing 12,417 images with labeled parking spaces.
"""

print("=" * 60)
print("Downloading PKLot Dataset (12,417 images, approximately 6.9 GB)")
print("=" * 60)

# Download using aria2c with 16 parallel connections for faster download
!aria2c -c -x 16 -s 16 -k 1M \
  -o PKLot.tar.gz \
  https://www.inf.ufpr.br/vri/databases/PKLot.tar.gz

# Verify download size
print("\nDownloaded file size:")
!ls -lh PKLot.tar.gz

# Extract the dataset
print("\nExtracting PKLot...")
!mkdir -p /content/real_datasets/PKLot
!tar -xzf PKLot.tar.gz -C /content/real_datasets/PKLot

# Verify extraction
print("\nPKLot extraction complete!")
print("Sample files:")
!find /content/real_datasets/PKLot -type f -name '*.jpg' | head -n 5

# Clean up archive to save space
!rm PKLot.tar.gz

"""## 7. PKLot Dataset Conversion to YOLO Format

Convert PKLot XML annotations to YOLO format and organize into train/val/test splits.
"""

def parseXmlAnnotationFile(xmlFilePath):
    """
    Parse PKLot XML annotation file (handles contour/point structure).

    Args:
        xmlFilePath (str): Path to the XML annotation file

    Returns:
        tuple: (annotations list, image path)
    """
    tree = etree.parse(xmlFilePath)
    root = tree.getroot()

    # Get image dimensions - try multiple locations
    imageFilePath = xmlFilePath.replace('.xml', '.jpg')

    # If image not found, try PKLotSegmented directory
    if not os.path.exists(imageFilePath):
        imageFilePath = imageFilePath.replace('/PKLot/', '/PKLotSegmented/')

    imageData = cv2.imread(imageFilePath)
    if imageData is not None:
        imageHeight, imageWidth = imageData.shape[:2]
    else:
        imageWidth = 1280
        imageHeight = 720

    parsedAnnotations = []

    # Parse each parking space in the XML
    for parkingSpace in root.findall('.//space'):
        isOccupied = parkingSpace.get('occupied', '0')
        classIdentifier = 1 if isOccupied == '1' else 0

        contourElement = parkingSpace.find('contour')
        if contourElement is not None:
            pointElements = contourElement.findall('point')
            if len(pointElements) >= 2:
                xCoordinates = [int(point.get('x', 0)) for point in pointElements]
                yCoordinates = [int(point.get('y', 0)) for point in pointElements]

                minX = min(xCoordinates)
                maxX = max(xCoordinates)
                minY = min(yCoordinates)
                maxY = max(yCoordinates)

                boundingBoxWidth = maxX - minX
                boundingBoxHeight = maxY - minY

                if boundingBoxWidth > 0 and boundingBoxHeight > 0:
                    # Calculate normalized YOLO format coordinates
                    normalizedCenterX = ((minX + maxX) / 2) / imageWidth
                    normalizedCenterY = ((minY + maxY) / 2) / imageHeight
                    normalizedWidth = boundingBoxWidth / imageWidth
                    normalizedHeight = boundingBoxHeight / imageHeight

                    parsedAnnotations.append((classIdentifier, normalizedCenterX,
                                             normalizedCenterY, normalizedWidth,
                                             normalizedHeight))

    return parsedAnnotations, imageFilePath

def convertPklotToYoloFormat(sourceDirectory, outputDirectory, splitRatios=(0.7, 0.15, 0.15)):
    """
    Convert PKLot dataset to YOLO format with train/val/test splits.

    Args:
        sourceDirectory (str): Source directory containing PKLot dataset
        outputDirectory (str): Output directory for YOLO format dataset
        splitRatios (tuple): Train, validation, test split ratios
    """
    print("Converting PKLot to YOLO format...")

    # Create directory structure for splits
    for datasetSplit in ['train', 'val', 'test']:
        os.makedirs(f"{outputDirectory}/{datasetSplit}/images", exist_ok=True)
        os.makedirs(f"{outputDirectory}/{datasetSplit}/labels", exist_ok=True)

    # Find all XML annotation files
    xmlAnnotationFiles = glob.glob(f"{sourceDirectory}/**/*.xml", recursive=True)
    print(f"Found {len(xmlAnnotationFiles)} annotation files")

    # Shuffle files for random split
    random.shuffle(xmlAnnotationFiles)

    totalFileCount = len(xmlAnnotationFiles)
    trainEndIndex = int(totalFileCount * splitRatios[0])
    validationEndIndex = trainEndIndex + int(totalFileCount * splitRatios[1])

    # Split files into train, validation, and test sets
    splitMapping = {
        'train': xmlAnnotationFiles[:trainEndIndex],
        'val': xmlAnnotationFiles[trainEndIndex:validationEndIndex],
        'test': xmlAnnotationFiles[validationEndIndex:]
    }

    # Process each split
    for splitName, fileList in splitMapping.items():
        print(f"\nProcessing {splitName} split ({len(fileList)} files)...")

        for xmlPath in tqdm(fileList, desc=f"Converting {splitName}"):
            # Parse annotations and get correct image path
            annotations, imagePath = parseXmlAnnotationFile(xmlPath)

            if not os.path.exists(imagePath):
                continue

            fileName = os.path.basename(imagePath)
            baseName = os.path.splitext(fileName)[0]

            destinationImagePath = f"{outputDirectory}/{splitName}/images/{fileName}"
            shutil.copy2(imagePath, destinationImagePath)

            destinationLabelPath = f"{outputDirectory}/{splitName}/labels/{baseName}.txt"
            with open(destinationLabelPath, 'w') as labelFile:
                for annotation in annotations:
                    labelFile.write(f"{annotation[0]} {annotation[1]:.6f} {annotation[2]:.6f} {annotation[3]:.6f} {annotation[4]:.6f}\n")

    print("\nConversion complete!")
    print(f"Train: {len(splitMapping['train'])} images")
    print(f"Val: {len(splitMapping['val'])} images")
    print(f"Test: {len(splitMapping['test'])} images")

"""## 8. Create YOLO Dataset Configuration File"""

# Create YAML configuration for YOLO training
datasetConfiguration = {
    'path': datasetDirectory,
    'train': 'pklot_yolo/train/images',
    'val': 'pklot_yolo/val/images',
    'test': 'pklot_yolo/test/images',
    'names': {
        0: 'Free',
        1: 'Occupied'
    },
    'nc': 2  # Number of classes
}

# Save configuration file
configurationPath = f"{datasetDirectory}/dataset.yaml"
with open(configurationPath, 'w') as configFile:
    yaml.dump(datasetConfiguration, configFile, default_flow_style=False)

print("Dataset configuration created")
print(f"Config file: {configurationPath}")
print("\nConfiguration:")
with open(configurationPath, 'r') as configFile:
    print(configFile.read())

# Execute conversion with fixed code
pklotSourcePath = "/content/real_datasets/PKLot/PKLot"
pklotOutputPath = f"{datasetDirectory}/pklot_yolo"

convertPklotToYoloFormat(pklotSourcePath, pklotOutputPath)

"""## 9. Custom Training Callback for Checkpoint Management"""

class CheckpointCallback:
    """
    Custom callback for periodic checkpoint saving during training.
    Fixes the issue with checkpoint saving by using direct torch.save.
    """

    def __init__(self, checkpointDirectory, saveInterval=5):
        """
        Initialize the checkpoint callback.

        Args:
            checkpointDirectory (str): Directory to save checkpoints
            saveInterval (int): Save checkpoint every N epochs
        """
        self.checkpointDirectory = checkpointDirectory
        self.saveInterval = saveInterval
        os.makedirs(checkpointDirectory, exist_ok=True)

    def __call__(self, trainer):
        """
        Called at the end of each training epoch.
        Saves checkpoint if current epoch is a multiple of saveInterval.

        Args:
            trainer: YOLO trainer object
        """
        currentEpochNumber = trainer.epoch + 1

        # Check if this epoch requires checkpoint save
        if currentEpochNumber % self.saveInterval == 0:
            checkpointFilePath = os.path.join(
                self.checkpointDirectory,
                f"checkpoint_epoch_{currentEpochNumber}.pt"
            )

            # Save model weights using torch.save directly
            checkpointData = {
                'epoch': currentEpochNumber,
                'model': trainer.model.state_dict(),
                'optimizer': trainer.optimizer.state_dict(),
                'best_fitness': trainer.best_fitness if hasattr(trainer, 'best_fitness') else None,
            }

            torch.save(checkpointData, checkpointFilePath)
            print(f"Checkpoint saved at epoch {currentEpochNumber}: {checkpointFilePath}")

print("Checkpoint callback class defined")

"""## 10. Train YOLO Model with Proper Checkpointing (Skip if Using Pretrained)"""

def trainYoloModel(configPath, trainingConfig, checkpointDir):
    """
    Train YOLO model with custom checkpoint callback.

    Args:
        configPath (str): Path to dataset YAML configuration
        trainingConfig (dict): Training hyperparameters
        checkpointDir (str): Directory for checkpoint storage

    Returns:
        results: Training results object
    """
    print("=" * 70)
    print("Starting Model Training")
    print("=" * 70)

    # Initialize model
    modelToTrain = YOLO(trainingConfig['model'])

    # Create checkpoint callback
    checkpointCallback = CheckpointCallback(
        checkpointDirectory=checkpointDir,
        saveInterval=trainingConfig['checkpoint_interval']
    )

    # Add callback using the correct ultralytics method
    modelToTrain.add_callback('on_train_epoch_end', checkpointCallback)

    # Train the model
    trainingResults = modelToTrain.train(
        data=configPath,
        epochs=trainingConfig['epochs'],
        batch=trainingConfig['batch'],
        imgsz=trainingConfig['imgsz'],
        patience=trainingConfig['patience'],
        optimizer=trainingConfig['optimizer'],
        lr0=trainingConfig['lr0'],
        device=trainingConfig['device'],
        project=datasetDirectory,
        name='parking_detector',
        exist_ok=True,
        save=True,
        verbose=True
    )

    print("\nTraining completed!")
    print(f"Best model saved to: {datasetDirectory}/parking_detector/weights/best.pt")

    return trainingResults

# Execute training or load pre-trained model based on configuration
if not USE_PRETRAINED_MODEL:
    print("Training new model...")
    trainingResults = trainYoloModel(
        configPath=configurationPath,
        trainingConfig=trainingConfiguration,
        checkpointDir=checkpointDirectory
    )
    bestYoloModelPath = f"{datasetDirectory}/parking_detector/weights/best.pt"
else:
    print(f"Using pre-trained model from: {PRETRAINED_MODEL_PATH}")
    bestYoloModelPath = PRETRAINED_MODEL_PATH
    trainingResults = None

print(f"Model path set to: {bestYoloModelPath}")

"""## 11. Evaluate YOLO Model Performance"""

def evaluateYoloModel(modelPath, dataConfigPath):
    """
    Evaluate trained model on validation set.

    Args:
        modelPath (str): Path to trained model weights
        dataConfigPath (str): Path to dataset configuration

    Returns:
        metrics: Validation metrics
    """
    print("=" * 70)
    print("YOLO Model Evaluation")
    print("=" * 70)

    # Load trained model
    evaluationModel = YOLO(modelPath)

    # Run validation
    validationMetrics = evaluationModel.val(
        data=dataConfigPath,
        split='val',
        save_json=True,
        save_hybrid=False
    )

    # Display results
    print("\nValidation Results:")
    print(f"mAP50: {validationMetrics.box.map50:.4f}")
    print(f"mAP50-95: {validationMetrics.box.map:.4f}")
    print(f"Precision: {validationMetrics.box.mp:.4f}")
    print(f"Recall: {validationMetrics.box.mr:.4f}")

    return validationMetrics

# Evaluate YOLO model
yoloValidationMetrics = evaluateYoloModel(bestYoloModelPath, configurationPath)

"""## 12. KNN Data Preparation"""

def prepareKnnDataset(imageDirectory, labelDirectory, maxSampleCount=2000, targetImageSize=(32, 32)):
    """
    Extract parking spaces and convert to raw pixel features for KNN.

    Args:
        imageDirectory (str): Directory containing images
        labelDirectory (str): Directory containing YOLO format labels
        maxSampleCount (int): Maximum number of samples to extract
        targetImageSize (tuple): Target size for resizing parking spaces

    Returns:
        tuple: (features array, labels array)
    """
    print(f"\nExtracting parking spaces from images")
    print(f"Directory: {imageDirectory}")

    extractedFeatures = []
    extractedLabels = []

    imageFileList = glob.glob(f"{imageDirectory}/*.jpg")
    print(f"Processing {len(imageFileList)} images...")

    sampleCounter = 0

    for imagePath in tqdm(imageFileList, desc="Extracting features"):
        # Stop collecting samples but let progress bar finish
        if sampleCounter >= maxSampleCount:
            continue

        currentImage = cv2.imread(imagePath)
        if currentImage is None:
            continue

        imageHeight, imageWidth = currentImage.shape[:2]

        baseFileName = os.path.splitext(os.path.basename(imagePath))[0]
        labelFilePath = f"{labelDirectory}/{baseFileName}.txt"

        if not os.path.exists(labelFilePath):
            continue

        # Read YOLO format labels
        with open(labelFilePath, 'r') as labelFile:
            for annotationLine in labelFile:
                annotationParts = annotationLine.strip().split()
                if len(annotationParts) != 5:
                    continue

                classIdentifier = int(annotationParts[0])
                centerX, centerY, boxWidth, boxHeight = map(float, annotationParts[1:])

                # Convert YOLO format to pixel coordinates
                pixelX1 = int((centerX - boxWidth/2) * imageWidth)
                pixelY1 = int((centerY - boxHeight/2) * imageHeight)
                pixelX2 = int((centerX + boxWidth/2) * imageWidth)
                pixelY2 = int((centerY + boxHeight/2) * imageHeight)

                # Ensure coordinates are within bounds
                pixelX1 = max(0, pixelX1)
                pixelY1 = max(0, pixelY1)
                pixelX2 = min(imageWidth, pixelX2)
                pixelY2 = min(imageHeight, pixelY2)

                regionOfInterest = currentImage[pixelY1:pixelY2, pixelX1:pixelX2]

                if regionOfInterest.size == 0:
                    continue

                # Resize and flatten to create feature vector
                resizedRegion = cv2.resize(regionOfInterest, targetImageSize)
                grayscaleRegion = cv2.cvtColor(resizedRegion, cv2.COLOR_BGR2GRAY)
                flattenedFeatures = grayscaleRegion.flatten() / 255.0  # Normalize

                extractedFeatures.append(flattenedFeatures)
                extractedLabels.append(classIdentifier)
                sampleCounter += 1

    featuresArray = np.array(extractedFeatures)
    labelsArray = np.array(extractedLabels)

    print(f"\nDataset prepared:")
    print(f"Total samples: {len(featuresArray)}")
    print(f"Free spaces (class 0): {np.sum(labelsArray == 0)}")
    print(f"Occupied spaces (class 1): {np.sum(labelsArray == 1)}")
    print(f"Feature dimensions: {featuresArray.shape[1] if len(featuresArray) > 0 else 0} pixels")

    return featuresArray, labelsArray

"""## 13. Train KNN Model"""

def trainKnnModel(trainingFeatures, trainingLabels, validationFeatures=None, validationLabels=None, neighborCount=5):
    """
    Train KNN model for parking space classification.

    Args:
        trainingFeatures: Training feature array
        trainingLabels: Training labels array
        validationFeatures: Validation feature array (optional)
        validationLabels: Validation labels array (optional)
        neighborCount (int): Number of neighbors for KNN

    Returns:
        KNeighborsClassifier: Trained KNN model
    """
    print(f"\nTraining KNN Model")
    print(f"k = {neighborCount} neighbors")

    # Initialize KNN classifier
    knnClassifier = KNeighborsClassifier(
        n_neighbors=neighborCount,
        weights='distance',
        algorithm='ball_tree',
        n_jobs=-1
    )

    # Train the model
    knnClassifier.fit(trainingFeatures, trainingLabels)

    # Training accuracy
    trainingPredictions = knnClassifier.predict(trainingFeatures)
    trainingAccuracy = accuracy_score(trainingLabels, trainingPredictions)
    print(f"Training Accuracy: {trainingAccuracy:.4f}")

    # Validation accuracy if data provided
    if validationFeatures is not None and validationLabels is not None:
        validationPredictions = knnClassifier.predict(validationFeatures)
        validationAccuracy = accuracy_score(validationLabels, validationPredictions)
        print(f"Validation Accuracy: {validationAccuracy:.4f}")

        # Print detailed classification report
        print("\nClassification Report:")
        classNames = ['Free', 'Occupied']
        print(classification_report(validationLabels, validationPredictions, target_names=classNames))

        # Confusion matrix
        confusionMatrixData = confusion_matrix(validationLabels, validationPredictions)
        print("\nConfusion Matrix:")
        print(confusionMatrixData)

    return knnClassifier

"""## 14. Execute KNN Training Pipeline"""

print("\n" + "="*70)
print("STEP 1: PREPARE KNN DATASET")
print("="*70)

# Prepare training data
knnTrainingFeatures, knnTrainingLabels = prepareKnnDataset(
    imageDirectory=f"{datasetDirectory}/pklot_yolo/train/images",
    labelDirectory=f"{datasetDirectory}/pklot_yolo/train/labels",
    maxSampleCount=2000,
    targetImageSize=(32, 32)
)

# Prepare validation data
knnValidationFeatures, knnValidationLabels = prepareKnnDataset(
    imageDirectory=f"{datasetDirectory}/pklot_yolo/val/images",
    labelDirectory=f"{datasetDirectory}/pklot_yolo/val/labels",
    maxSampleCount=500,
    targetImageSize=(32, 32)
)

print("\n" + "="*70)
print("STEP 2: TRAIN KNN MODEL")
print("="*70)

# Train KNN
trainedKnnModel = trainKnnModel(
    trainingFeatures=knnTrainingFeatures,
    trainingLabels=knnTrainingLabels,
    validationFeatures=knnValidationFeatures,
    validationLabels=knnValidationLabels,
    neighborCount=5
)

# Save KNN model
knnModelSavePath = f"{datasetDirectory}/knn_parking_model.pkl"
joblib.dump(trainedKnnModel, knnModelSavePath)
print(f"\nKNN model saved to: {knnModelSavePath}")

"""## 15. Compare YOLO and KNN Models"""

def compareModels(yoloModelPath, knnClassifier, testImageDirectory, testLabelDirectory, sampleCount=50):
    """
    Compare YOLO and KNN performance side-by-side.

    Args:
        yoloModelPath (str): Path to YOLO model
        knnClassifier: Trained KNN model
        testImageDirectory (str): Test images directory
        testLabelDirectory (str): Test labels directory
        sampleCount (int): Number of samples to evaluate

    Returns:
        tuple: (KNN statistics, YOLO statistics)
    """
    print("\nComparing YOLO vs KNN Performance")
    print("="*70)

    yoloModel = YOLO(yoloModelPath)

    testImageFiles = glob.glob(f"{testImageDirectory}/*.jpg")
    selectedSamples = random.sample(testImageFiles, min(sampleCount, len(testImageFiles)))

    yoloStatistics = {'correct': 0, 'total': 0, 'confidences': []}
    knnStatistics = {'correct': 0, 'total': 0}

    print(f"Processing {len(selectedSamples)} images...")

    for imagePath in tqdm(selectedSamples, desc="Comparing models"):
        testImage = cv2.imread(imagePath)
        if testImage is None:
            continue

        imageHeight, imageWidth = testImage.shape[:2]

        baseFileName = os.path.splitext(os.path.basename(imagePath))[0]
        labelPath = f"{testLabelDirectory}/{baseFileName}.txt"

        if not os.path.exists(labelPath):
            continue

        # YOLO predictions
        yoloResults = yoloModel(imagePath, conf=0.25, verbose=False)[0]
        yoloBoxes = {}
        for box in yoloResults.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            predictedClass = int(box.cls[0])
            yoloBoxes[(x1, y1, x2, y2)] = (predictedClass, confidence)

        # Process each ground truth parking space
        with open(labelPath, 'r') as labelFile:
            for line in labelFile:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue

                trueClass = int(parts[0])
                centerX, centerY, width, height = map(float, parts[1:])

                x1 = int((centerX - width/2) * imageWidth)
                y1 = int((centerY - height/2) * imageHeight)
                x2 = int((centerX + width/2) * imageWidth)
                y2 = int((centerY + height/2) * imageHeight)

                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(imageWidth, x2)
                y2 = min(imageHeight, y2)

                roi = testImage[y1:y2, x1:x2]

                if roi.size == 0:
                    continue

                # KNN prediction
                resizedRoi = cv2.resize(roi, (32, 32))
                grayRoi = cv2.cvtColor(resizedRoi, cv2.COLOR_BGR2GRAY)
                features = grayRoi.flatten() / 255.0
                knnPrediction = knnClassifier.predict([features])[0]

                knnStatistics['total'] += 1
                if knnPrediction == trueClass:
                    knnStatistics['correct'] += 1

                # YOLO prediction (match with IoU)
                bestIou = 0
                yoloPrediction = None
                yoloConfidence = 0

                for (bx1, by1, bx2, by2), (cls, conf) in yoloBoxes.items():
                    intersectionX1 = max(x1, bx1)
                    intersectionY1 = max(y1, by1)
                    intersectionX2 = min(x2, bx2)
                    intersectionY2 = min(y2, by2)

                    intersectionArea = max(0, intersectionX2 - intersectionX1) * max(0, intersectionY2 - intersectionY1)
                    box1Area = (x2 - x1) * (y2 - y1)
                    box2Area = (bx2 - bx1) * (by2 - by1)
                    unionArea = box1Area + box2Area - intersectionArea

                    iou = intersectionArea / unionArea if unionArea > 0 else 0

                    if iou > bestIou:
                        bestIou = iou
                        yoloPrediction = cls
                        yoloConfidence = conf

                if yoloPrediction is not None:
                    yoloStatistics['total'] += 1
                    yoloStatistics['confidences'].append(yoloConfidence)
                    if yoloPrediction == trueClass:
                        yoloStatistics['correct'] += 1

    # Print results
    print("\n" + "="*70)
    print("COMPARISON RESULTS")
    print("="*70)

    knnAccuracy = knnStatistics['correct'] / knnStatistics['total'] if knnStatistics['total'] > 0 else 0
    yoloAccuracy = yoloStatistics['correct'] / yoloStatistics['total'] if yoloStatistics['total'] > 0 else 0

    print(f"\nKNN Performance:")
    print(f"Accuracy: {knnAccuracy:.4f} ({knnStatistics['correct']}/{knnStatistics['total']})")

    print(f"\nYOLO Performance:")
    print(f"Accuracy: {yoloAccuracy:.4f} ({yoloStatistics['correct']}/{yoloStatistics['total']})")
    if yoloStatistics['confidences']:
        print(f"Average Confidence: {np.mean(yoloStatistics['confidences']):.4f}")

    return knnStatistics, yoloStatistics

print("\n" + "="*70)
print("STEP 3: COMPARE MODELS")
print("="*70)

# Compare YOLO vs KNN
knnStats, yoloStats = compareModels(
    yoloModelPath=bestYoloModelPath,
    knnClassifier=trainedKnnModel,
    testImageDirectory=f"{datasetDirectory}/pklot_yolo/test/images",
    testLabelDirectory=f"{datasetDirectory}/pklot_yolo/test/labels",
    sampleCount=50
)

"""## 16. Visualization Functions"""

def visualizeComparison(knnStats, yoloStats, outputDirectory):
    """
    Create comparison visualizations.

    Args:
        knnStats (dict): KNN model statistics
        yoloStats (dict): YOLO model statistics
        outputDirectory (str): Directory to save visualizations
    """
    print("\nCreating visualizations...")

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Accuracy comparison
    modelNames = ['KNN', 'YOLO']
    accuracies = [
        knnStats['correct'] / knnStats['total'] if knnStats['total'] > 0 else 0,
        yoloStats['correct'] / yoloStats['total'] if yoloStats['total'] > 0 else 0
    ]
    barColors = ['#e74c3c', '#2ecc71']

    bars = axes[0].bar(modelNames, accuracies, color=barColors, width=0.6)
    axes[0].set_ylabel('Accuracy', fontsize=13, fontweight='bold')
    axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[0].set_ylim([0, 1.05])
    axes[0].grid(True, alpha=0.3, axis='y', linestyle='--')

    for i, v in enumerate(accuracies):
        axes[0].text(i, v + 0.03, f'{v:.3f}', ha='center', fontsize=12, fontweight='bold')

    # YOLO confidence distribution
    if yoloStats['confidences']:
        axes[1].hist(yoloStats['confidences'], bins=20, color='#2ecc71', alpha=0.7, edgecolor='black')
        meanConfidence = np.mean(yoloStats['confidences'])
        axes[1].axvline(meanConfidence, color='red', linestyle='--',
                       linewidth=2, label=f"Mean: {meanConfidence:.3f}")
        axes[1].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')
        axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')
        axes[1].set_title('YOLO Confidence Distribution', fontsize=14, fontweight='bold')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3, linestyle='--')
        axes[1].text(0.5, 0.95, 'KNN has no confidence scores',
                    ha='center', va='top', transform=axes[1].transAxes,
                    style='italic', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    saveFilePath = f"{outputDirectory}/model_comparison.png"
    plt.savefig(saveFilePath, dpi=150, bbox_inches='tight')
    print(f"Saved: {saveFilePath}")
    plt.show()

def visualizeKnnLearnedPatterns(knnModel, trainingFeatures, trainingLabels, outputDirectory, sampleCount=20):
    """
    Visualize what KNN has learned by showing average patterns.

    Args:
        knnModel: Trained KNN model
        trainingFeatures: Training features array
        trainingLabels: Training labels array
        outputDirectory (str): Directory to save visualizations
        sampleCount (int): Number of samples to show
    """
    print("\nVisualizing KNN learned patterns...")

    # Get samples of each class
    freeSamples = trainingFeatures[trainingLabels == 0][:sampleCount]
    occupiedSamples = trainingFeatures[trainingLabels == 1][:sampleCount]

    # Calculate average parking space for each class
    averageFreeSpace = np.mean(freeSamples, axis=0).reshape(32, 32)
    averageOccupiedSpace = np.mean(occupiedSamples, axis=0).reshape(32, 32)

    fig, axes = plt.subplots(2, sampleCount//2, figsize=(20, 6))
    fig.suptitle('KNN Training Samples: What the Model Learned', fontsize=16, fontweight='bold')

    # Show free parking spaces
    for i in range(sampleCount//2):
        if i < len(freeSamples):
            axes[0, i].imshow(freeSamples[i].reshape(32, 32), cmap='gray')
            axes[0, i].set_title(f'Free {i+1}', fontsize=10)
            axes[0, i].axis('off')

    # Show occupied parking spaces
    for i in range(sampleCount//2):
        if i < len(occupiedSamples):
            axes[1, i].imshow(occupiedSamples[i].reshape(32, 32), cmap='gray')
            axes[1, i].set_title(f'Occupied {i+1}', fontsize=10)
            axes[1, i].axis('off')

    plt.tight_layout()
    saveFilePath = f"{outputDirectory}/knn_training_samples.png"
    plt.savefig(saveFilePath, dpi=150, bbox_inches='tight')
    print(f"Saved: {saveFilePath}")
    plt.show()

    # Show average patterns
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(averageFreeSpace, cmap='hot')
    axes[0].set_title('Average FREE Parking Space', fontsize=13, fontweight='bold')
    axes[0].axis('off')

    axes[1].imshow(averageOccupiedSpace, cmap='hot')
    axes[1].set_title('Average OCCUPIED Parking Space', fontsize=13, fontweight='bold')
    axes[1].axis('off')

    # Difference
    differencePlot = averageOccupiedSpace - averageFreeSpace
    imPlot = axes[2].imshow(differencePlot, cmap='RdBu', vmin=-0.5, vmax=0.5)
    axes[2].set_title('Difference (Occupied - Free)', fontsize=13, fontweight='bold')
    axes[2].axis('off')
    plt.colorbar(imPlot, ax=axes[2], fraction=0.046, pad=0.04)

    plt.tight_layout()
    saveFilePath = f"{outputDirectory}/knn_average_patterns.png"
    plt.savefig(saveFilePath, dpi=150, bbox_inches='tight')
    print(f"Saved: {saveFilePath}")
    plt.show()

def visualizePredictionsComparison(yoloModelPath, knnModel, imageDirectory, labelDirectory, outputDirectory, imageCount=3):
    """
    Show side-by-side predictions from both models.

    Args:
        yoloModelPath (str): Path to YOLO model
        knnModel: Trained KNN model
        imageDirectory (str): Directory containing images
        labelDirectory (str): Directory containing labels
        outputDirectory (str): Directory to save visualizations
        imageCount (int): Number of images to visualize
    """
    print("\nCreating prediction comparison visualizations...")

    yoloModel = YOLO(yoloModelPath)
    imageFileList = glob.glob(f"{imageDirectory}/*.jpg")
    sampleImages = random.sample(imageFileList, min(imageCount, len(imageFileList)))

    for imageIndex, imagePath in enumerate(sampleImages):
        currentImage = cv2.imread(imagePath)
        if currentImage is None:
            continue

        imageRgb = cv2.cvtColor(currentImage, cv2.COLOR_BGR2RGB)
        imageHeight, imageWidth = currentImage.shape[:2]

        baseFileName = os.path.splitext(os.path.basename(imagePath))[0]
        labelPath = f"{labelDirectory}/{baseFileName}.txt"

        if not os.path.exists(labelPath):
            continue

        # Create figure
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle(f'Prediction Comparison - {baseFileName}', fontsize=14, fontweight='bold')

        # Original image
        axes[0].imshow(imageRgb)
        axes[0].set_title('Original Image', fontsize=12, fontweight='bold')
        axes[0].axis('off')

        # YOLO predictions
        yoloImageCopy = imageRgb.copy()
        yoloResults = yoloModel(imagePath, conf=0.25, verbose=False)[0]
        for box in yoloResults.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            predictedClass = int(box.cls[0])
            confidence = float(box.conf[0])

            boxColor = (0, 255, 0) if predictedClass == 0 else (255, 0, 0)
            cv2.rectangle(yoloImageCopy, (x1, y1), (x2, y2), boxColor, 2)
            cv2.putText(yoloImageCopy, f"{confidence:.2f}", (x1, y1-5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, boxColor, 2)

        axes[1].imshow(yoloImageCopy)
        axes[1].set_title('YOLO Predictions', fontsize=12, fontweight='bold')
        axes[1].axis('off')

        # KNN predictions
        knnImageCopy = imageRgb.copy()
        with open(labelPath, 'r') as labelFile:
            for line in labelFile:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue

                centerX, centerY, width, height = map(float, parts[1:])

                x1 = int((centerX - width/2) * imageWidth)
                y1 = int((centerY - height/2) * imageHeight)
                x2 = int((centerX + width/2) * imageWidth)
                y2 = int((centerY + height/2) * imageHeight)

                roi = currentImage[max(0, y1):min(imageHeight, y2), max(0, x1):min(imageWidth, x2)]

                if roi.size > 0:
                    resizedRoi = cv2.resize(roi, (32, 32))
                    grayRoi = cv2.cvtColor(resizedRoi, cv2.COLOR_BGR2GRAY)
                    features = grayRoi.flatten() / 255.0
                    knnPrediction = knnModel.predict([features])[0]

                    boxColor = (0, 255, 0) if knnPrediction == 0 else (255, 0, 0)
                    cv2.rectangle(knnImageCopy, (x1, y1), (x2, y2), boxColor, 2)

        axes[2].imshow(knnImageCopy)
        axes[2].set_title('KNN Predictions', fontsize=12, fontweight='bold')
        axes[2].axis('off')

        plt.tight_layout()
        saveFilePath = f"{outputDirectory}/prediction_comparison_{imageIndex+1}.png"
        plt.savefig(saveFilePath, dpi=150, bbox_inches='tight')
        print(f"Saved: {saveFilePath}")
        plt.show()

"""## 17. Execute All Visualizations"""

# Create output directory for visualizations
outputVisualizationDirectory = f"{datasetDirectory}/visualizations"
os.makedirs(outputVisualizationDirectory, exist_ok=True)

print("\n" + "="*70)
print("STEP 4: VISUALIZATIONS")
print("="*70)

# Create all visualizations
visualizeComparison(knnStats, yoloStats, outputVisualizationDirectory)
visualizeKnnLearnedPatterns(trainedKnnModel, knnTrainingFeatures, knnTrainingLabels,
                            outputVisualizationDirectory, sampleCount=20)
visualizePredictionsComparison(bestYoloModelPath, trainedKnnModel,
                               f"{datasetDirectory}/pklot_yolo/test/images",
                               f"{datasetDirectory}/pklot_yolo/test/labels",
                               outputVisualizationDirectory, imageCount=3)

"""## 18. Final Summary and Results"""

print("\n" + "="*70)
print("COMPLETE PIPELINE EXECUTION SUMMARY")
print("="*70)

print(f"\nConfiguration:")
print(f"  - Using Pretrained Model: {USE_PRETRAINED_MODEL}")
if USE_PRETRAINED_MODEL:
    print(f"  - Pretrained Model Path: {PRETRAINED_MODEL_PATH}")
else:
    print(f"  - Trained New Model")

print(f"\nAll visualizations saved to: {outputVisualizationDirectory}")
print("\nGenerated files:")
print("  - model_comparison.png")
print("  - knn_training_samples.png")
print("  - knn_average_patterns.png")
print("  - prediction_comparison_*.png")

print("\nModel Paths:")
print(f"  - YOLO Model: {bestYoloModelPath}")
print(f"  - KNN Model: {knnModelSavePath}")

print("\n" + "="*70)
print("Pipeline execution completed successfully!")
print("="*70)